{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mteb in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: datasets>=2.2.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (2.7.1)\n",
      "Requirement already satisfied: jsonlines in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (4.0.0)\n",
      "Requirement already satisfied: numpy in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (1.24.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (2.29.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (1.10.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (2.2.2)\n",
      "Requirement already satisfied: torch in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (4.65.0)\n",
      "Requirement already satisfied: rich in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from mteb) (12.6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (10.0.1)\n",
      "Requirement already satisfied: dill<0.3.7 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (1.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (3.1.0)\n",
      "Requirement already satisfied: multiprocess in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from datasets>=2.2.0->mteb) (6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->mteb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->mteb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->mteb) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->mteb) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.2->mteb) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.2->mteb) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.0->mteb) (4.32.1)\n",
      "Requirement already satisfied: torchvision in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.0->mteb) (0.15.2)\n",
      "Requirement already satisfied: nltk in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.0->mteb) (3.5)\n",
      "Requirement already satisfied: sentencepiece in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.0->mteb) (0.1.99)\n",
      "Requirement already satisfied: filelock in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from torch->mteb) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from torch->mteb) (4.6.2)\n",
      "Requirement already satisfied: sympy in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from torch->mteb) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from torch->mteb) (2.5.1)\n",
      "Requirement already satisfied: jinja2 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from torch->mteb) (3.1.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from jsonlines->mteb) (22.1.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from rich->mteb) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from rich->mteb) (2.15.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.2.0->mteb) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.2.0->mteb) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.2.0->mteb) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.0->mteb) (0.3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch->mteb) (2.1.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from networkx->torch->mteb) (4.4.2)\n",
      "Requirement already satisfied: click in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers>=2.2.0->mteb) (8.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets>=2.2.0->mteb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets>=2.2.0->mteb) (2022.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch->mteb) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=2.2.0->mteb) (9.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/willhathaway/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=2.2.0->mteb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mteb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: trained: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of '/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    676\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0c/rktcvrz54rd9hjwm0vq_fx900000gn/T/ipykernel_88578/283201690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/e5-base-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m# sta = embedding_model(AutoModel.from_pretrained(\"models/e5-base-v2\"), AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\"), device=device, inference=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# mult = embedding_model(AutoModel.from_pretrained(\"models/multilingual-e5-small\"), AutoTokenizer.from_pretrained(\"tokenizers/multilingual-e5-small\"), device=device, inference=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    697\u001b[0m                     \u001b[0;34mf\"Can't load the configuration of '{pretrained_model_name_or_path}'. If you were trying to load it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0;34m\" from 'https://huggingface.co/models', make sure you don't have a local directory with the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of '/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "# load from disk\n",
    "class embedding_model:\n",
    "    def __init__(self, model, tokenizer, device, inference=False):\n",
    "        self.model = model.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        if inference:\n",
    "            self.model.eval()\n",
    "            self.model.requires_grad_(False)\n",
    "\n",
    "    def average_pool(last_hidden_states: torch.Tensor,\n",
    "                 attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "    \n",
    "    def encode(self, sentences, batch_size=32):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            batch_sentences = sentences[i:i+batch_size]\n",
    "            for sentence in batch_sentences:\n",
    "                embedding = self.__call__(sentence)\n",
    "                # Take the first element of the tensor to get a 1D tensor\n",
    "                embedding = embedding[0]\n",
    "                embeddings.append(embedding.cpu().numpy())\n",
    "        return embeddings\n",
    "\n",
    "    def __call__(self, data):\n",
    "        tokens_and_mask = self.tokenizer(data, return_tensors='pt', padding=True, truncation=True, max_length=512).to(self.device)\n",
    "        model_output = self.model(tokens_and_mask[\"input_ids\"], attention_mask=tokens_and_mask[\"attention_mask\"])\n",
    "        embedding = embedding_model.average_pool(model_output.last_hidden_state, attention_mask=tokens_and_mask[\"attention_mask\"])\n",
    "        # normalize the embedding\n",
    "        embedding = embedding / embedding.norm(dim=-1, keepdim=True)\n",
    "        return embedding    \n",
    "\n",
    "dyn = embedding_model(AutoModel.from_pretrained(\"/Users/willhathaway/classes/6.s898/mulitlingual-embeddingss/webteam_work/trained/e5-base-v2-esp-150k\"), AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\"), device=device, inference=True)\n",
    "# sta = embedding_model(AutoModel.from_pretrained(\"models/e5-base-v2\"), AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\"), device=device, inference=True)\n",
    "# mult = embedding_model(AutoModel.from_pretrained(\"models/multilingual-e5-small\"), AutoTokenizer.from_pretrained(\"tokenizers/multilingual-e5-small\"), device=device, inference=True)\n",
    "\n",
    "\n",
    "\n",
    "# put into dictionary\n",
    "models = {\n",
    "    \"dyn\": dyn,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mteb import MTEB\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"dyn\"\n",
    "\n",
    "# model = SentenceTransformer(model_name)\n",
    "evaluation = MTEB(tasks=[\"Banking77Classification\"], task_langs=[\"en\", \"de\"])\n",
    "results = evaluation.run(models[model_name], output_folder=f\"results/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Banking77Classification': {'mteb_version': '1.1.1',\n",
       "  'dataset_revision': '0fd18e25b25c072e09e0d92ab615fda904d66300',\n",
       "  'mteb_dataset_name': 'Banking77Classification',\n",
       "  'test': {'accuracy': 0.7663636363636364,\n",
       "   'f1': 0.7571862523229754,\n",
       "   'accuracy_stderr': 0.008049329276696824,\n",
       "   'f1_stderr': 0.009676908587947413,\n",
       "   'main_score': 0.7663636363636364,\n",
       "   'evaluation_time': 242.59}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
