{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "I want to use [e5-small-v2](https://huggingface.co/intfloat/e5-small-v2) or [e5-base-v2](https://huggingface.co/intfloat/e5-base-v2) and compare it against [e5 multilingual](https://huggingface.co/intfloat/multilingual-e5-small) before and after training an adaptive layer on it.\n",
    "\n",
    "Model stats:\n",
    "\n",
    "| Model | # params | # layers | emb size |\n",
    "| --- | --- | --- | --- |\n",
    "| e5-small-v2 | 33M | 12 | 384 |\n",
    "| e5 multilingual | 118M | 12 | 384 |\n",
    "| e5-base-v2 | 118M | 12 | 768 |\n",
    "\n",
    "## The Data\n",
    "We want to use translated datasets, probably only for the languages used in e5-multilingual, or maybe just one. Kinda weird because models are different. I'm also curious how much the multilingual dataset differentiates between the same sentence in different languages\n",
    "\n",
    "Can find the data [here](https://huggingface.co/datasets/allenai/nllb)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# load in model folders from disk\n",
    "# try:\n",
    "#     small_v2 = AutoModel.from_pretrained(\"models/e5-small-v2\")\n",
    "#     multilingual = AutoModel.from_pretrained(\"models/multilingual-e5-small\")\n",
    "#     base_v2 = AutoModel.from_pretrained(\"models/e5-base-v2\")\n",
    "#     small_v2_tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/e5-small-v2\")\n",
    "#     multilingual_tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/multilingual-e5-small\")\n",
    "#     base_v2_tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\")\n",
    "# except (FileNotFoundError, OSError):\n",
    "#     small_v2 = AutoModel.from_pretrained(\"intfloat/e5-small-v2\")\n",
    "#     multilingual = AutoModel.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "#     base_v2 = AutoModel.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "#     small_v2_tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-small-v2\")\n",
    "#     multilingual_tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-small\")\n",
    "#     base_v2_tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "#     # save to disk in new folders models and tokenizers\n",
    "#     small_v2.save_pretrained(\"models/e5-small-v2\")\n",
    "#     multilingual.save_pretrained(\"models/multilingual-e5-small\")\n",
    "#     base_v2.save_pretrained(\"models/e5-base-v2\")\n",
    "#     small_v2_tokenizer.save_pretrained(\"tokenizers/e5-small-v2\")\n",
    "#     multilingual_tokenizer.save_pretrained(\"tokenizers/multilingual-e5-small\")\n",
    "#     base_v2_tokenizer.save_pretrained(\"tokenizers/e5-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the models in the class so they're easier to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding_model:\n",
    "    def __init__(self, model, tokenizer, device):\n",
    "        self.model = model.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def average_pool(last_hidden_states: torch.Tensor,\n",
    "                 attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "    def __call__(self, data):\n",
    "        tokens_and_mask = self.tokenizer(data, return_tensors='pt', padding=True, truncation=True, max_length=512).to(self.device)\n",
    "        model_output = self.model(tokens_and_mask[\"input_ids\"], attention_mask=tokens_and_mask[\"attention_mask\"])\n",
    "        embedding = embedding_model.average_pool(model_output.last_hidden_state, attention_mask=tokens_and_mask[\"attention_mask\"])\n",
    "        # normalize the embedding\n",
    "        embedding = embedding / embedding.norm(dim=-1, keepdim=True)\n",
    "        return embedding    \n",
    "\n",
    "\n",
    "\n",
    "# create embedding models\n",
    "# small_v2_model = embedding_model(small_v2, small_v2_tokenizer, device)\n",
    "# multilingual_model = embedding_model(multilingual, multilingual_tokenizer, device)\n",
    "# base_v2_model = embedding_model(base_v2, base_v2_tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# note: esp-eng dataset is 38GB\n",
    "test_dataset = load_dataset(\"allenai/nllb\", \"eng_Latn-spa_Latn\", split=\"train\", streaming=True).take(1000)\n",
    "\n",
    "train_dataset = load_dataset(\"allenai/nllb\", \"eng_Latn-spa_Latn\", split=\"train\", streaming=True).skip(1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: How does multi-lingual treat translated text pairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reduced vectors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# English sentences\n",
    "sentences = [\n",
    "    \"This is an example sentence\",\n",
    "    \"Each sentence is converted\",\n",
    "    \"into a vector\",\n",
    "    \"Such vectors can be compared\",\n",
    "    \"similar sentences will be close\",\n",
    "    \"while different sentences are expected to be far apart\",\n",
    "]\n",
    "# spanish sentences (translated from english)\n",
    "sentences_es = [\n",
    "    \"Esta es una oración de ejemplo\",\n",
    "    \"Cada oración se convierte\",\n",
    "    \"en un vector\",\n",
    "    \"Tales vectores se pueden comparar\",\n",
    "    \"se espera que las oraciones similares estén cerca\",\n",
    "    \"mientras que las oraciones diferentes deben estar muy separadas\",\n",
    "]\n",
    "\n",
    "# en = torch.tensor(multilingual.encode(sentences))\n",
    "# es = torch.tensor(multilingual.encode(sentences_es))\n",
    "# en_and_es = torch.cat((en, es), dim=0)\n",
    "# print(F.cosine_similarity(en, es, dim=1))\n",
    "# map = UMAP(n_components=2, n_neighbors=5, min_dist=0.3, metric=\"cosine\")\n",
    "# reduced = map.fit(en_and_es)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.scatter(reduced.embedding_[:6, 0], reduced.embedding_[:6, 1], c=\"blue\")\n",
    "# plt.scatter(reduced.embedding_[6:, 0], reduced.embedding_[6:, 1], c=\"red\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:  It doesn't seem to notice the difference at least not obviously. It doesn't outweigh everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n",
      "tensor(1., device='mps:0', grad_fn=<NormBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# make a copy of the model\n",
    "base_v2_model\n",
    "dynamic = AutoModel.from_pretrained(\"models/e5-base-v2\").to(device)\n",
    "dynamic_tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\")\n",
    "dynamic_model = embedding_model(dynamic, dynamic_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14.1293], device='mps:0', grad_fn=<NormBackward1>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/781.25]\n",
      "Loss: 0.010403558611869812\n",
      "Average inter-model similarity: 0.9887597672641277\n",
      "Average intra-lang similarity: 0.9559698179364204\n",
      "Epoch [101/781.25]\n",
      "Loss: 0.00917188823223114\n",
      "Average inter-model similarity: 0.9959704056382179\n",
      "Average intra-lang similarity: 0.9540795646607876\n",
      "Epoch [201/781.25]\n",
      "Loss: 0.008555032312870026\n",
      "Average inter-model similarity: 0.9960418380796909\n",
      "Average intra-lang similarity: 0.9550326094031334\n",
      "Epoch [301/781.25]\n",
      "Loss: 0.008802447468042374\n",
      "Average inter-model similarity: 0.9956105276942253\n",
      "Average intra-lang similarity: 0.9574507139623165\n",
      "Epoch [401/781.25]\n",
      "Loss: 0.008591266348958015\n",
      "Average inter-model similarity: 0.9952964968979359\n",
      "Average intra-lang similarity: 0.957591962069273\n",
      "Epoch [501/781.25]\n",
      "Loss: 0.008262112736701965\n",
      "Average inter-model similarity: 0.99581703171134\n",
      "Average intra-lang similarity: 0.9582218788564205\n",
      "Epoch [601/781.25]\n",
      "Loss: 0.007295450195670128\n",
      "Average inter-model similarity: 0.9958999119699001\n",
      "Average intra-lang similarity: 0.9587362334132195\n",
      "Epoch [701/781.25]\n",
      "Loss: 0.008080177009105682\n",
      "Average inter-model similarity: 0.9958053007721901\n",
      "Average intra-lang similarity: 0.9597854018211365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.008968481793999672,\n",
       " [(0.9887597672641277, 0.9559698179364204),\n",
       "  (0.9959704056382179, 0.9540795646607876),\n",
       "  (0.9960418380796909, 0.9550326094031334),\n",
       "  (0.9956105276942253, 0.9574507139623165),\n",
       "  (0.9952964968979359, 0.957591962069273),\n",
       "  (0.99581703171134, 0.9582218788564205),\n",
       "  (0.9958999119699001, 0.9587362334132195),\n",
       "  (0.9958053007721901, 0.9597854018211365)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DYNAMIC_SCALING = 10e-2\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "\n",
    "    def forward(self, native_fixed, native_dynamic, foreign_dynamic):\n",
    "        # We want the native_fixed and native_dynamic to be close together\n",
    "        native_sim = F.cosine_similarity(native_fixed, native_dynamic)\n",
    "        dynamic_sim = F.cosine_similarity(native_dynamic, foreign_dynamic)\n",
    "        loss_contrastive = torch.mean(1 - native_sim) + DYNAMIC_SCALING * torch.mean(1 - dynamic_sim)  \n",
    "\n",
    "        return loss_contrastive\n",
    "\n",
    "\n",
    "def evaluate(dynamic_model, fixed_model, dataset, batch_size=32, criterion=ContrastiveLoss, langs=[\"eng_Latn\", \"spa_Latn\"], device=device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given dataset\n",
    "    Returns the average loss\n",
    "    \"\"\"\n",
    "    dataset = dataset.with_format(\"torch\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    inter_model_loss_total = 0\n",
    "    intra_lang_loss_dynamic_total = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Forward pass\n",
    "        fixed_native = fixed_model(batch[\"translation\"][langs[0]])\n",
    "        dynamic_native = dynamic_model(batch[\"translation\"][langs[0]])\n",
    "        dynamic_foreign = dynamic_model(batch[\"translation\"][langs[1]])\n",
    "        \n",
    "        inter_model_loss = torch.mean(F.cosine_similarity(fixed_native, dynamic_native))\n",
    "        intra_lang_loss_dynamic = torch.mean(F.cosine_similarity(dynamic_native, dynamic_foreign))\n",
    "        \n",
    "        inter_model_loss_total += inter_model_loss.item()\n",
    "        intra_lang_loss_dynamic_total += intra_lang_loss_dynamic.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_inter_model_loss = inter_model_loss_total / num_batches\n",
    "    avg_intra_lang_loss_dynamic = intra_lang_loss_dynamic_total / num_batches\n",
    "\n",
    "    return avg_inter_model_loss, avg_intra_lang_loss_dynamic        \n",
    "\n",
    "def train(fixed_model, dynamic_model, num_text_pairs, evals, train_dataset=train_dataset, test_dataset=test_dataset, lr=.0001, batch_size=32, criterion=ContrastiveLoss(), langs=[\"eng_Latn\", \"spa_Latn\"], device=device):\n",
    "    \"\"\"\n",
    "    Lang[0] is the native language\n",
    "    Lang[1] is the foreign language\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(dynamic_model.model.parameters(), lr=lr)\n",
    "    \n",
    "    # Convert the dataset to torch format and create a DataLoader\n",
    "    train_dataset = train_dataset.with_format(\"torch\")\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Forward pass\n",
    "        fixed_native = fixed_model(batch[\"translation\"][langs[0]])\n",
    "        dynamic_native = dynamic_model(batch[\"translation\"][langs[0]])\n",
    "        dynamic_foreign = dynamic_model(batch[\"translation\"][langs[1]])\n",
    "        loss = criterion(fixed_native, dynamic_native, dynamic_foreign)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i * batch_size > num_text_pairs:\n",
    "            break\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{i+1}/{num_text_pairs/batch_size}]')\n",
    "            print(f'Loss: {loss.item()}')\n",
    "            test = evaluate(dynamic_model, fixed_model, test_dataset, batch_size=batch_size, criterion=criterion, langs=langs, device=device)\n",
    "            print(f\"Average inter-model similarity: {test[0]}\")\n",
    "            print(f\"Average intra-lang similarity: {test[1]}\")\n",
    "            evals.append(test)\n",
    "            #TODO don't hardcode this\n",
    "            dynamic_model.model.save_pretrained(f\"training/e5-base-v2-{i * batch_size}\")\n",
    "\n",
    "        # print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "    return loss.item(), evals\n",
    "\n",
    "# dynamic = embedding_model(AutoModel.from_pretrained(\"models/e5-base-v2\"), AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\"), device)\n",
    "fixed = embedding_model(AutoModel.from_pretrained(\"models/e5-base-v2\"), AutoTokenizer.from_pretrained(\"tokenizers/e5-base-v2\"), device)\n",
    "# multi = embedding_model(AutoModel.from_pretrained(\"models/multilingual-e5-small\"), AutoTokenizer.from_pretrained(\"tokenizers/multilingual-e5-small\"), device)\n",
    "evals = []\n",
    "train(fixed, dynamic, num_text_pairs=50_000, batch_size=64, evals=evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store dynamic.model in a folder\n",
    "dynamic.model.save_pretrained(\"trained/e5-base-v2-150k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is an example sentence', 'Esta es una oración de ejemplo')\n",
      "fixed 0.7975223660469055\n",
      "dynamic 0.8925096988677979\n",
      "fixed v dynamic 0.9899151921272278\n",
      "('Each sentence is converted', 'Cada oración se convierte')\n",
      "fixed 0.7486991882324219\n",
      "dynamic 0.8775215744972229\n",
      "fixed v dynamic 0.9962867498397827\n",
      "('into a vector', 'en un vector')\n",
      "fixed 0.9113370180130005\n",
      "dynamic 0.9575779438018799\n",
      "fixed v dynamic 0.9964996576309204\n",
      "('Such vectors can be compared', 'Tales vectores se pueden comparar')\n",
      "fixed 0.856069803237915\n",
      "dynamic 0.9698941707611084\n",
      "fixed v dynamic 0.9961637258529663\n",
      "('similar sentences will be close', 'se espera que las oraciones similares estén cerca')\n",
      "fixed 0.8379346132278442\n",
      "dynamic 0.8799442648887634\n",
      "fixed v dynamic 0.9934095144271851\n",
      "('while different sentences are expected to be far apart', 'mientras que las oraciones diferentes deben estar muy separadas')\n",
      "fixed 0.8365286588668823\n",
      "dynamic 0.8870798945426941\n",
      "fixed v dynamic 0.9920188188552856\n"
     ]
    }
   ],
   "source": [
    "for pair in zip(sentences, sentences_es):\n",
    "    print(pair)\n",
    "    fix = fixed(pair)\n",
    "    dyn = dynamic(pair)\n",
    "    print(\"fixed\", F.cosine_similarity(fix[0].unsqueeze(0), fix[1].unsqueeze(0)).item())\n",
    "    print(\"dynamic\", F.cosine_similarity(dyn[0].unsqueeze(0), dyn[1].unsqueeze(0)).item())\n",
    "    print(\"fixed v dynamic\", F.cosine_similarity(fix[0].unsqueeze(0), dyn[0].unsqueeze(0)).item())\n",
    "\n",
    "\n",
    "# a = dynamic_model.embed([\"espanol\", \"spanish\"], device=device)\n",
    "# b = base_v2_model.embed([\"espanol\", \"spanish\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9289], device='mps:0', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cosine_similarity(dynamic(\"el niño triste\"), dynamic(\"the sad boy\"), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9369], device='mps:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(dynamic(\"I love you\"), dynamic(\"I really love you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9073], device='mps:0', grad_fn=<SumBackward1>)\n",
      "tensor([0.8750], device='mps:0', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cosine_similarity(a[0].unsqueeze(0), a[1].unsqueeze(0)))\n",
    "print(torch.cosine_similarity(b[0].unsqueeze(0), b[1].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed(multilingual.to(device), base_v2_tokenizer, [\"espanol\", \"spanish\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.iterable_dataset.IterableDataset at 0x7ff200778cd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
